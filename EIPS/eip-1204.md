---
eip: 
title: Detecting Bribers On-Chain
status: Draft
type: Meta
author: Stefan Ionescu <stefanionescu@protonmail.com>
created: 2018-07-09
---

## Simple Summary

This document proposes to mix human voters with bots in order to detect bribing attacks and in some limited scenarios punish the attackers.

## Abstract

A major problem with most, if not all on-chain voting schemes is that they are prone to bribing. Even if bribing in itself can't be stopped for now, there is a way to deceive attackers into thinking they won. Bots that act like humans can collect bribes and announce fraud at the proper time to make all bribes useless after collecting as much money as possible from attackers.

## Motivation

This proposal is necessary because the Ethereum protocol is already used by communities around the world to vote and govern themselves. These communities do not have any guarantee that the result of their votes is not manipulated and thus a strategy to detect bribers should be set up.

## Specification

Imagine a country with 1000 people and a voter participation rate of 55% on every election (average rate over the last 10 years of elections).

Suppose that this year the country wants to organize an election on a blockchain. There are __X__ candidates that run on the election and we expect the same historic voter participation rate.

In order to detect attackers, a group of voters can come together and perform multi-party computation in order to generate __Y__ bots, where __Y__ is a multiple of __X__. The computation needs to be done so that even if the attackers take part in generating the bots, we still manage to correctly spawn the bots. These bots have the mission to act like real people, let themselves bribed and report the bribery at the ideal moment. Thus, we cannot rely on a centralized party to execute the bots’ code (as they may be the attackers themselves), and the MPC group (or any other distributed party) will be in charge of activating the bots.

Each of the bots will vote for one particular candidate, and given that __Y__ is a multiple of __X__, bots can agree to vote in a way that does not change the result of the election. All bots need to vote (especially if all voters are verified by ID) in order to appear as real as possible.

Naturally, the more bots there are, the greater the chance of detecting an attacker is. The bots will be part of a DAO where we can’t see how many of them were created, how they act or what vote each bot will cast. In this scenario, Enigma would help with its secret contracts.

The bots need to be able to adapt to both on-chain attacks (a bribing smart contract sending a micro-transaction as a signal for a voter to check its code) and off-chain ones (bots need to talk with the attackers).

An ideal (but unrealistic) scenario for us is that the attacker bribes a bot, the bot votes as the attacker wants and receives the payout right away. Also, suppose that the bots can change their vote if it’s not equivalent to the one they intended to cast when they were generated.

In case the bots can somehow render all bribes useless (bribes received by both humans and bots) before the voting ends, they can coordinate so that they wait until time __T1__, where __T1__ is equal to __T2 - m__. __T2__ is the time when the voting ends and __m__ is a randomly generated variable (that is, preferably, secret). __m__ should be as small as possible so that bots maximize the chance of getting bribes before they announce the attackers.

If we don’t have a mechanism to render the bribed votes as useless, the bots can simply wait until __T2__ for maximum impact (getting as much money as possible from the attackers).

The coins collected from the attackers can then be distributed to people who participated in MPC or simply burned. In short, this scenario is equivalent to slashing (the attackers bribed but did not get the results they wanted).

The disadvantage of waiting until the end and not having a bribe canceling strategy is that the vote needs to be rescheduled.

Coming to the real world where things tend to be messier, attackers can deposit each bribe in an escrow where the bribed voters need to wait until time __T2 + n__ to get their reward. The attackers can also specify that no announcement of fraud can be made if the bribed voters will ever get to see their money.

Bots can still announce the bribing, but the attackers will not get slashed, unless the announcement is made after time __T2 + n__. In some cases, __n__ can equal, for example, one month for the escrow to be available so that the bots can then report, make all votes useless and also slash.

This timespan is too big and cumbersome to wait for. If attackers don’t get slashed because the bots reported them too early, they can bribe again if the vote is rescheduled.

## Rationale

This strategy was chosen due to the effectiveness of AI to detect fraud in real life situations. AI, executed in a trusless manner, can lead the way towards policing the blockchain to ensure vote integrity.

## Copyright
Copyright and related rights waived via
[CC0](https://creativecommons.org/publicdomain/zero/1.0/).